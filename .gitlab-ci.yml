---
stages:
 - build-es-synonyms
 - test
 - build
 - staging
 - data-integration-staging
 - production
 - data-integration-production

# Image source available on https://forgemia.inra.fr/urgi-is/docker-rare
# It contains a JDK 8 and a Chrome browser
# Node, NPM and Yarn are installed by Gradle
image: urgi/docker-browsers:latest

# Disable the Gradle daemon for Continuous Integration servers as correctness
# is usually a priority over speed in CI environments. Using a fresh
# runtime for each build is more reliable since the runtime is completely
# isolated from any previous builds.
variables:
 GRADLE_OPTS: "-Dorg.gradle.daemon=false"
 GRADLE_USER_HOME: $CI_PROJECT_DIR/.gradle
 GIT_LFS_SKIP_SMUDGE: "1"
 ELASTIC_VERSION: "6.6.2"
 IMAGE_TAG: $CI_COMMIT_REF_SLUG

build-es-synonyms:
 # There are three methods to enable the use of docker build and docker run during jobs; each with their own tradeoffs
 # (more details here: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html)
 # docker-in-docker (dind) approach is used here.
 # https://stackoverflow.com/questions/47280922/role-of-docker-in-docker-dind-service-in-gitlab-ci
 # The runner should be executed in privileged mode.
 # It is recommended to use dind with TLS enabled.
 image: docker:19.03.1
 stage: build-es-synonyms
 services:
  - docker:19.03.1-dind
 script:
  # The IMAGE_TAG is used to distinguish dev image (with SHA1 as a tag) from the stable one (with 'latest' as a tag).
  # 'latest' tag is used only for an image built from master branch.
  - if [ "$CI_COMMIT_BRANCH" == "master" ]; then IMAGE_TAG="latest"; fi
  - cd data/synonyms
  - docker build --build-arg ELASTIC_VERSION=${ELASTIC_VERSION} -t registry.forgemia.inra.fr/urgi-is/data-discovery/elasticsearch-synonyms:${IMAGE_TAG} .
  - docker login registry.forgemia.inra.fr -u $CONTAINER_REGISTRY_USERNAME -p $CONTAINER_REGISTRY_TOKEN
  # TODO: remove the old SHA image before pushing the new one? (https://gitlab.com/gitlab-org/gitlab-foss/issues/25322)
  - docker push registry.forgemia.inra.fr/urgi-is/data-discovery/elasticsearch-synonyms:${IMAGE_TAG}
 only:
  changes:
   - data/synonyms/*

test:
 stage: test
 # the backend tests need an elasticsearch instance
 services:
   # even if that would be ideal
   # we can't just launch the service with just elasticsearch:6.3.1
   # because we need to pass some variables, but they are passed to _all_ containers
   # so they fail the start of other docker images like urgi/docker-browsers
   # the only solution is to override the entrypoint of the service and pass the arguments manually
   - name: registry.forgemia.inra.fr/urgi-is/data-discovery/elasticsearch-synonyms:${IMAGE_TAG}
     alias: elasticsearch
     # discovery.type=single-node
     # single-node is necessary to start in development mode
     # so there will be no bootstrap checks that would fail on CI
     # especially the error regarding
     # `max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]`
     command:
      - /bin/sh
      - -c
      - "export PATH=/usr/share/elasticsearch/bin:$PATH ;
         exec chroot --userspec=1000 / elasticsearch -Ediscovery.type=single-node -Ecluster.name=elasticsearch"
 script: ./gradlew --parallel test
 cache:
   key: "$CI_COMMIT_REF_NAME"
   policy: pull-push
   paths:
     - .gradle
     - frontend/.gradle/
     - frontend/node_modules/
 artifacts:
  reports:
   junit:
    - ./backend/build/test-results/test/TEST-*.xml
    - ./frontend/karma-junit-tests-report/TEST*.xml
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*

lint:
 stage: test
 script: ./gradlew :frontend:lint

.build-app: &build_app
 # Hidden job which serves as a template for following
 # jobs below. See https://docs.gitlab.com/ee/ci/yaml/#anchors
 stage: build
 script:
  - ./gradlew assemble -Papp=${APP_NAME}
 artifacts:
  paths:
   - backend/build/libs/${APP_NAME}.jar
  expire_in: 1 week
 cache:
  key: "${CI_COMMIT_REF_NAME}"
  policy: pull-push
  paths:
   - .gradle
   - frontend/.gradle/
   - frontend/node_modules/
 only:
  changes:
   - backend/src/**/*
   - backend/build.gradle.kts
   - frontend/**/*
   - build.gradle.kts
   - docker.env

build-rare:
 variables:
  APP_NAME: ${RARE_APP_NAME}
 <<: *build_app           # Merge the contents of the 'build_app' alias

build-wheatis:
 variables:
  APP_NAME: ${WHEATIS_APP_NAME}
 <<: *build_app           # Merge the contents of the 'build_app' alias

build-data-discovery:
 variables:
  APP_NAME: ${DATADISCOVERY_APP_NAME}
 <<: *build_app           # Merge the contents of the 'build_app' alias

.ssh-initialization-before-script: &ssh-initialization-before-script
 before_script:
  # SSH initialization
  - eval $(ssh-agent -s)
  - ssh-add <(echo "${SSH_PRIVATE_KEY}")
  - ssh -o StrictHostKeyChecking=no root@${SERVER_IP} 'echo "Successfully connected on $(hostname)"'

.deploy-to-vm: &deploy_to_vm
 # Hidden job which serves as template for executed jobs below.
 # See https://docs.gitlab.com/ee/ci/yaml/#anchors
 retry: 2
 <<: *ssh-initialization-before-script
 script:
  # Copy jar to the server
  - scp ./backend/build/libs/${APP_NAME}.jar root@${SERVER_IP}:/opt/bootapp/${APP_NAME}-${ENV}.jar
  # Restarting service with the updated jar and the according Spring profiles enabled
  - ssh root@${SERVER_IP} "systemctl restart bootapp@${APP_NAME}-${ENV}"
  - eval $(ssh-agent -k)
  - echo "Deploy and index done. Application should be available at http://${SERVER_IP}:${APP_PORT}/${APP_CONTEXT}"

.variables-rare-beta: &variables-rare-beta
 variables:
  ENV: beta
  APP_NAME: rare
  APP_PORT: ${BETA_RARE_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: ${APP_NAME}-${ENV}

.variables-rare-staging: &variables-rare-staging
 variables:
  ENV: staging
  APP_NAME: rare
  APP_PORT: ${STAGING_RARE_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: ${APP_NAME}-${ENV}

.variables-rare-prod: &variables-rare-prod
 variables:
  ENV: prod
  APP_NAME: rare
  APP_PORT: ${PROD_RARE_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_PROD_HOST}
  ES_HOSTS: ${ES_PROD_HOSTS}
  ES_PORT: ${ES_PROD_PORT}
  APP_CONTEXT: ${APP_NAME}

.variables-wheatis-beta: &variables-wheatis-beta
 variables:
  ENV: beta
  APP_NAME: wheatis
  APP_PORT: ${BETA_WHEATIS_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: ${APP_NAME}-${ENV}

.variables-wheatis-staging: &variables-wheatis-staging
 variables:
  ENV: staging
  APP_NAME: wheatis
  APP_PORT: ${STAGING_WHEATIS_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: ${APP_NAME}-${ENV}

.variables-wheatis-prod: &variables-wheatis-prod
 variables:
  ENV: prod
  APP_NAME: wheatis
  APP_PORT: ${PROD_WHEATIS_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_PROD_HOST}
  ES_HOSTS: ${ES_PROD_HOSTS}
  ES_PORT: ${ES_PROD_PORT}
  APP_CONTEXT: ${APP_NAME}

.variables-data-discovery-beta: &variables-data-discovery-beta
 variables:
  ENV: beta
  APP_NAME: data-discovery
  APP_PORT: ${BETA_DATADISCOVERY_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: data-discovery-${ENV}

.variables-data-discovery-staging: &variables-data-discovery-staging
 variables:
  ENV: staging
  APP_NAME: data-discovery
  APP_PORT: ${STAGING_DATADISCOVERY_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_DEV_HOST}
  ES_HOSTS: ${ES_DEV_HOSTS}
  ES_PORT: ${ES_DEV_PORT}
  APP_CONTEXT: data-discovery-${ENV}

.variables-data-discovery-prod: &variables-data-discovery-prod
 variables:
  ENV: prod
  APP_NAME: data-discovery
  APP_PORT: ${PROD_DATADISCOVERY_PORT}
  SERVER_IP: ${SERVER_IP}
  ES_HOST: ${ES_PROD_HOST}
  ES_HOSTS: ${ES_PROD_HOSTS}
  ES_PORT: ${ES_PROD_PORT}
  APP_CONTEXT: data-discovery

deploy-rare-to-beta:
 stage: staging
 <<: *variables-rare-beta
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - branches
 except:
  refs:
   - master
 allow_failure: false # mandatory to block the execution of the pipeline

deploy-rare-to-staging:
 stage: staging
 <<: *variables-rare-staging
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master

deploy-rare-to-prod:
 stage: production
 <<: *variables-rare-prod
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master
 when: manual
 allow_failure: false

deploy-wheatis-to-beta:
 stage: staging
 <<: *variables-wheatis-beta
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - branches
 except:
  refs:
   - master
 allow_failure: false

deploy-wheatis-to-staging:
 stage: staging
 <<: *variables-wheatis-staging
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master

deploy-wheatis-to-prod:
 stage: production
 <<: *variables-wheatis-prod
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master
 when: manual
 allow_failure: false

deploy-data-discovery-to-beta:
 stage: staging
 <<: *variables-data-discovery-beta
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - branches
 except:
  refs:
   - master
 allow_failure: false

deploy-data-discovery-to-staging:
 stage: staging
 <<: *variables-data-discovery-staging
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master

deploy-data-discovery-to-prod:
 stage: production
 <<: *variables-data-discovery-prod
 <<: *deploy_to_vm
 only:
  changes:
   - backend/src/**/*
   - frontend/**/*
  refs:
   - master
 when: manual
 allow_failure: false

.data-integration: &data-integration
 # do not retry to avoid overloading the Elasticsearch cluster
 retry: 0
 script:
  # Do fetch of GIT LFS files only for data integration steps for given app
  - git checkout $CI_COMMIT_REF_NAME
  - git pull
  - git lfs pull -I "data/${APP_NAME}/*.gz"
  - git lfs pull -I "data/${APP_NAME}/suggestions/*.gz"
  # Deleting old indexes before reindexing from scratch
  #  - curl -s -XDELETE ${ES_HOST}:${ES_PORT}/*${APP_NAME}-${ENV}-* ; echo
  - ./scripts/index.sh -host ${ES_HOST} -app ${APP_NAME} -env ${ENV} ; sleep 1 ; echo
 environment:
  # take care that some variables cannot be expanded according to where they are
  # defined. Info: https://forgemia.inra.fr/help/ci/variables/where_variables_can_be_used.md
  name: ${ENV}-${APP_NAME}
  # DO NOT specify environment's url here if it is already defined in the
  # Environments settings, it would cause the build not being visible in the
  # Deployments view because of a known bug:
  # https://gitlab.com/gitlab-org/gitlab-ce/issues/26537
 when: manual

data-integration-rare-beta:
 stage: data-integration-staging
 <<: *variables-rare-beta
 <<: *data-integration
 only:
  changes:
   - data/rare/*.json.gz
   - data/synonyms/*
  refs:
   - branches
 except:
  refs:
   - master

data-integration-rare-staging:
 stage: data-integration-staging
 <<: *variables-rare-staging
 <<: *data-integration
 only:
  changes:
   - data/rare/*.json.gz
   - data/synonyms/*
  refs:
   - master

data-integration-rare-prod:
 stage: data-integration-production
 <<: *variables-rare-prod
 <<: *data-integration
 only:
  changes:
   - data/rare/*.json.gz
   - data/synonyms/*
  refs:
   - master

data-integration-wheatis-beta:
 stage: data-integration-staging
 <<: *variables-wheatis-beta
 <<: *data-integration
 only:
  changes:
   - data/wheatis/*.json.gz
   - data/synonyms/*
  refs:
   - branches
 except:
  refs:
   - master

data-integration-wheatis-staging:
 stage: data-integration-staging
 <<: *variables-wheatis-staging
 <<: *data-integration
 only:
  changes:
   - data/wheatis/*.json.gz
   - data/synonyms/*
  refs:
   - master

data-integration-wheatis-prod:
 stage: data-integration-production
 <<: *variables-wheatis-prod
 <<: *data-integration
 only:
  changes:
   - data/wheatis/*.json.gz
   - data/synonyms/*
  refs:
   - master

data-integration-data-discovery-beta:
 stage: data-integration-staging
 <<: *variables-data-discovery-beta
 <<: *data-integration
 only:
  changes:
   - data/data-discovery/*.json.gz
   - data/synonyms/*
  refs:
   - branches
 except:
  refs:
   - master

data-integration-data-discovery-staging:
 stage: data-integration-staging
 <<: *variables-data-discovery-staging
 <<: *data-integration
 only:
  changes:
   - data/data-discovery/*.json.gz
   - data/synonyms/*
  refs:
   - master

data-integration-data-discovery-prod:
 stage: data-integration-production
 <<: *variables-data-discovery-prod
 <<: *data-integration
 only:
  changes:
   - data/data-discovery/*.json.gz
   - data/synonyms/*
  refs:
   - master

# Should find a way to authorize such pipeline once at a time in order to avoid
# multiple restart of services, elasticsearch cluster or reindexing
